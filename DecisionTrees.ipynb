{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 10304)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "path=\"/home/merna/Downloads/dataSet/orl_faces/\"\n",
    "D = []\n",
    "labels = []\n",
    "for i in range(1,41):   \n",
    "    for j in range(1,11):\n",
    "        img = plt.imread(path+\"/s\"+str(i)+\"/\"+str(j)+\".pgm\")\n",
    "        #plt.imshow(img)\n",
    "        listM = np.array(img).flatten()\n",
    "        #listM = np.concatenate((listM,[i]),axis=0)\n",
    "        D.append(listM)\n",
    "        labels.append(i) \n",
    "        \n",
    "D = np.matrix(D) \n",
    "labels = np.array(labels)\n",
    "print(D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Dataset into Training and Test sets\n",
    "train_vector = D[0::2,:]\n",
    "train_label = labels[0::2]\n",
    "test_vector = D[1::2,:]\n",
    "test_label = labels[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_counts(data):\n",
    "    dic_class = {}  # a dictionary of label -> count.\n",
    "    for i in range(0,len(data)):\n",
    "        row= np.array(data[i]).flatten()\n",
    "        # in our dataset format, the label is always the last column\n",
    "        l = row[len(row)-1]\n",
    "        if l not in dic_class:\n",
    "            dic_class[l] = 0\n",
    "        else:\n",
    "            dic_class[l] += 1\n",
    "    return dic_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question_class:\n",
    "\n",
    "    #Hold the feature and the value\n",
    "\n",
    "    def __init__(self, feature, value):\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "\n",
    "    def check(self, row):\n",
    "        value_feature = row[self.feature]\n",
    "        return value_feature >= self.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(data, question):\n",
    "   \n",
    "    false_dataset = []\n",
    "    true_dataset = []\n",
    "    for row in data:\n",
    "        if question.check(row):\n",
    "            true_dataset.append(row)\n",
    "        else:\n",
    "            false_dataset.append(row)\n",
    "    return true_dataset, false_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def Entropy(data):\n",
    "    #get the cardinality of each class \n",
    "    dic = class_counts(data)\n",
    "    entropy=0\n",
    "    for i in dic:\n",
    "        probability_of_the_class = dic[i] / float(len(data))\n",
    "        if probability_of_the_class > 0:\n",
    "            entropy -= (probability_of_the_class)*math.log(probability_of_the_class)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(left, right, cur_entropy):\n",
    "    left_probability = float(len(left)) / (len(left) + len(right))\n",
    "    right_probability = float(len(right)) / (len(left) + len(right))\n",
    "    return cur_entropy - left_probability * Entropy(left) + right_probability * Entropy(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(data):\n",
    "    #keep track of the highest information gain\n",
    "    best_gain = 0\n",
    "    #keep value of best split\n",
    "    best_question = None\n",
    "    #Main Class Entropy (before splitting-->needed to calculate information Gain)\n",
    "    cur_entropy = Entropy(data)\n",
    "    #number of feature we subtract one (column for label)\n",
    "    features = len(data[0]) - 1  \n",
    "\n",
    "    for feature in range(features):  # for each feature\n",
    "        #get unique values in data\n",
    "        values = set([data[feature] for row in data])  \n",
    "        #\n",
    "        for i in range(1,len(values)):  # for each value\n",
    "            #get midpoint\n",
    "            value = ((values[i]+ values[i-1])/2)\n",
    "            #make an object carry featur and value\n",
    "            question = Qestion_class(feature, value)\n",
    "\n",
    "            # try splitting the dataset\n",
    "            true_dataset, false_dataset = partition(data, question)\n",
    "\n",
    "            # Skip this split if it doesn't divide the dataset\n",
    "            if len(true_dataset) == 0 or len(false_dataset) == 0:\n",
    "                continue\n",
    "\n",
    "            # Calculate the information gain from this split\n",
    "            information_gain_of_this_split = information_gain(true_dataset, false_dataset, cur_entropy)\n",
    "\n",
    "            # You actually can use '>' instead of '>=' here\n",
    "            # but I wanted the tree to look a certain way for our\n",
    "            # toy dataset.\n",
    "            if information_gain_of_this_split >= best_gain:\n",
    "                best_gain, best_question = information_gain_of_this_split, question\n",
    "\n",
    "    return best_gain, best_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "class internal_node:\n",
    "  #hold question it asked , its false and true branches.\n",
    "\n",
    "    def __init__(self,question,true_branch,false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "class leaf_node:\n",
    "    \"\"\"A Leaf node classifies data.\n",
    "\n",
    "    This holds a dictionary of class (e.g., \"Apple\") -> number of times\n",
    "    it appears in the rows from the training data that reach this leaf.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        index=0;\n",
    "        value=0\n",
    "        dic=class_counts(data)\n",
    "        for keys,values in dic.items():\n",
    "            if values>value:\n",
    "              value=values\n",
    "              index=keys\n",
    "        self.predictions = dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(data):\n",
    "\n",
    "    #find the best split by calculating information gain and pick the highest one \n",
    "    information_gain_value, question = find_best_split(data)\n",
    "\n",
    "   #base case no information gain i cant ask more questions \n",
    "    if information_gain_value == 0:\n",
    "        return leaf_node(data)\n",
    "\n",
    "   #partition dataset to true and false tuples based on the question i asked \n",
    "    true_dataset, false_dataset = partition(data, question)\n",
    "\n",
    "    # Repeat step on true dataset\n",
    "    true_branch = build_tree(true_dataset)\n",
    "\n",
    "    # repeat steps on false dataset\n",
    "    false_branch = build_tree(false_dataset)\n",
    "\n",
    "    #create a node that holds (true partition, false partition , question)\n",
    "    return internal_node(question, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root is a reference to the root of decision tree\n",
    "root = build_tree(train_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_label(row_data, node):\n",
    "    \"\"\"See the 'rules of recursion' above.\"\"\"\n",
    "\n",
    "    # Base case: we reached a leaf\n",
    "    #function returns True if the specified object is of the specified type, otherwise False.\n",
    "    if isinstance(node, leaf_node):\n",
    "        return node.predictions\n",
    "\n",
    "    # Decide whether to follow the true-branch or the false-branch.\n",
    "    # Compare the feature / value stored in the node,\n",
    "    # to the example we're considering.\n",
    "    if node.question.check(row_data):\n",
    "        return classify(row_data, node.true_branch)\n",
    "    else:\n",
    "        return classify(row_data, node.false_branch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predicted_label=[]\n",
    "#for i in range(0,len(test_vector)):\n",
    "predicted_label.append(guess_label(test_vector[i], root))\n",
    "print(test_label)\n",
    "print(predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765\n",
      "0.725\n",
      "0.92\n",
      "0.845\n",
      "0.965\n",
      "0.915\n",
      "0.965\n",
      "0.925\n"
     ]
    }
   ],
   "source": [
    "#random_forest:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "lists = [10,30,100,300]\n",
    "list2= ['entropy','gini']\n",
    "for n in lists:\n",
    "    for method in list2:\n",
    "       clf = RandomForestClassifier(n_estimators=n,criterion=method)\n",
    "       clf.fit(train_vector, train_label)  \n",
    "       output_labels = clf.predict(test_vector)\n",
    "    #calculate accuracy\n",
    "       print(accuracy_score(output_labels, test_label))\n",
    "#best tuning trees=300 and criterion = gini"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
